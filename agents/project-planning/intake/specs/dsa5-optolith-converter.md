# DSA5 → Optolith NPC Converter

## Context
- Product / initiative: Aventuria Impromptu companion tools
- Author: Product Owner Agent
- Date: 2025-10-14

## Problem Statement
Game masters preparing DSA5 sessions spend time transcribing adventure stat blocks into Optolith so they can reuse NPCs inside the official tool. Manual re-entry is error-prone because stat blocks use prose, abbreviations, and shorthand that do not map 1:1 to Optolith hero JSON. We need an automated converter that ingests the published stat block text, resolves all mechanical elements against a curated Optolith dataset derived from the official data ZIP (without redistributing the original archive), and emits a single-hero JSON that Optolith accepts without manual clean-up.

## Goals
- Parse German-language DSA5 adventure stat blocks into a structured internal representation that preserves both mechanical and narrative elements.
- Resolve all rules references (talents, combat techniques, advantages/disadvantages, special abilities, languages/scripts, liturgies, blessings, equipment) against IDs from a curated dataset generated by processing the Optolith data ZIP supplied by maintainers.
- Apply normalization logic so ambiguous or legacy stat block wording maps to canonical Optolith entries (e.g. tradition naming, leveled abilities with roman numerals).
- Infer secondary values where the stat block omits explicit data but rules allow deterministic reconstruction (e.g. deriving CT from AT and MU bonuses).
- Produce a single hero JSON payload that passes Optolith’s import validation without further manual intervention.
- Preserve narrative details in safe note fields whenever no canonical mapping exists, ensuring nothing is silently dropped.
- Provide a repeatable extraction pipeline that transforms the official Optolith data ZIP into the converter’s derived dataset without bundling the source archive.

## Non-Goals
- Deriving resource pools, initiative strings, movement, or other values Optolith can compute automatically after import.
- Supporting batches or multi-hero payloads; every run emits exactly one hero structure.
- Translating stat block text into other languages; input and output remain German per Optolith expectations.
- Distributing the original Optolith data ZIP with the application; the workflow only ships derived datasets.

## User Flows / Scenarios
1. A GM pastes a single NPC stat block from a published DSA5 adventure, regenerates the derived dataset from the latest Optolith data ZIP, and runs the converter. Importing the generated JSON into Optolith results in a fully populated NPC with correct talents, abilities, and notes.
2. A rules editor bulk checks an adventure by running multiple stat blocks through the converter. When the stat block references a talent or ability missing from the derived dataset, the converter reports the unresolved item with actionable guidance so the editor can update the curated data or adjust the stat block.

## Functional Requirements
- Accept plain text input containing a single DSA5 stat block; handle common formatting artifacts such as extra whitespace, bullet-like punctuation, and line breaks.
- Provide an extraction process (CLI or script) that ingests the Optolith DSA5 data ZIP supplied by maintainers and emits a normalized dataset (e.g. JSON) with canonical IDs, select-option metadata (`sid`/`sid2`), labels, and schema version info.
- Parse stat block sections (attributes, combat stats, talents, advantages/disadvantages, special abilities, spells/rituals/liturgies, equipment, social status, narrative notes).
- Implement normalization rules to reconcile shorthand names to canonical Optolith entries (e.g. “Tradition (Gott)” → “Tradition (Gottkirche)”, support for tiered roman numerals, language/script handling via SA_29/SA_27).
- Infer missing but derivable values such as combat technique based on attack/defense and attribute bonuses, standard blessings when only a count is present, or specialization metadata through SA_9.
- Populate narrative-only information into Optolith-safe note fields without introducing Markdown or unsupported characters.
- Emit a JSON structure that matches Optolith’s single-hero schema, including required metadata fields and references to resolved IDs.
- Provide validation and error reporting for unresolved references, malformed stat blocks, or incompatible data ZIP versions, offering actionable remediation suggestions.
- Operate offline using the derived dataset; no network lookups are required once the extraction step has been completed.
- Document the extraction workflow so maintainers can refresh the dataset when Optolith releases updates.

## Technical Constraints
- Tool must consume the Optolith data ZIP supplied during maintenance and transform it into a derived dataset checked into the build or distributed separately.
- Output JSON must comply with the current Optolith import schema (version to be confirmed); deviations should be feature-flagged if schema changes.
- Parsing should accommodate German umlauts and sharp S; assume UTF-8 encoding for both input and output.
- The converter should be deliverable as a script or CLI compatible with the existing Node 20 toolchain unless another runtime is specified.
- Derived datasets must be deterministic so downstream builds can reproduce outputs for verification.

## Acceptance Criteria (High-Level)
- Given a representative DSA5 stat block and a derived dataset generated from the Optolith data ZIP, running the converter produces a JSON file that imports successfully into Optolith with all mechanical elements populated.
- When the stat block references an entity that cannot be resolved in the derived dataset, the converter reports the missing reference and preserves the text in the notes field instead of failing silently.
- Narrative sections from the stat block (e.g. appearance, motivation) remain accessible within the imported NPC via Optolith notes.
- Automated normalization handles at least the specified cases (tradition renaming, roman numeral tiers, language/script special abilities, specialization metadata).
- The extraction process documents the Optolith data ZIP version used and regenerates the derived dataset without manual edits.

## Risks & Assumptions
- The raw requirement references additional specification sections that are not available in the repository snapshot; further details may exist elsewhere.
- Optolith data schemas could change without notice; maintaining compatibility may require version detection and update cadence for the derived dataset pipeline.
- Stat blocks across published adventures are inconsistent; additional normalization or exception handling may be necessary beyond the cases listed.
- Product Owner confirmed that distributing the derived dataset (without the raw Optolith archive) complies with current licensing guidance.
- Redistribution of derived datasets must respect Optolith licensing; verify the transformation approach keeps us compliant while excluding raw assets.

## Open Questions
- What distribution format is expected (CLI, desktop UI, web app)? The raw note does not specify the delivery channel.
- Which Optolith import schema version should be targeted, and how should version mismatches be handled?
- Are there priority adventures or NPC archetypes we must support in the initial release?
- Should the converter provide batch processing or remain single-stat-block per invocation in the first iteration?
- How should we store and protect the maintainer-supplied Optolith data ZIP during extraction (e.g. encryption at rest, update verification)?
- The raw note mentions a “full specification continues” outside this file—where can we access the complete reference material?
- What is the process for updating the derived dataset when official Optolith releases change (ownership, cadence, testing)?

## Attachments
- Raw intake note: `agents/project-planning/intake/raw/20251014-dsa5-to-optolith-converter.md`
